name: Database Backup

on:
  schedule:
    - cron: '0 2 * * *'  # Daily at 2 AM UTC
  workflow_dispatch:

jobs:
  backup:
    runs-on: ubuntu-latest
    
    steps:
    - name: Backup Database
      env:
        DATABASE_URL: ${{ secrets.DATABASE_URL }}
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        S3_BUCKET: ${{ secrets.S3_BACKUP_BUCKET }}
      run: |
        timestamp=$(date +%Y%m%d_%H%M%S)
        backup_file="namaskah_backup_${timestamp}.sql"
        
        # Create backup
        pg_dump $DATABASE_URL > $backup_file
        
        # Compress
        gzip $backup_file
        
        # Upload to S3
        aws s3 cp ${backup_file}.gz s3://${S3_BUCKET}/backups/
        
        # Keep only last 7 days
        aws s3 ls s3://${S3_BUCKET}/backups/ | while read -r line; do
          createDate=$(echo $line | awk '{print $1" "$2}')
          createDate=$(date -d "$createDate" +%s)
          olderThan=$(date -d "7 days ago" +%s)
          if [[ $createDate -lt $olderThan ]]; then
            fileName=$(echo $line | awk '{print $4}')
            aws s3 rm s3://${S3_BUCKET}/backups/$fileName
          fi
        done
